{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b>:<br> This notebook is my understanding of chapter 10 of `Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow 2nd Edition` book written by `Aurelien Geron`, entitled as `Introduction to Artificial Neural Networks with Keras`.<br>\n",
    "While most of the markdown and also code blocks have been copied from the chapter's notebook, the arraingment and changes made to the whole project is personalized based on my knowledge and what I comprehended and learned from the book. I'm going to use this notebook as a reference, when I want to apply Neural Network on Machine Learning projects in the future.\n",
    "\n",
    "`Aurelien Geron`'s Github repository for the book can be found [here](https://github.com/ageron/handson-ml2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "In this notebook we are going to explore different techniques of applying Neural Networks on different Machine Learning problems. So, feel free to jump into any section you like and try the codes out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the fashion MNIST dataset. Keras has a number of functions to load popular datasets in `keras.datasets`. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_set_X_full, train_set_Y_full), (test_set_X, test_set_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_X_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_X_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255. (train_set_X only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set_X, train_set_X = train_set_X_full[:5000] / 255., train_set_X_full[5000:] / 255.\n",
    "valid_set_Y, train_set_Y = train_set_Y_full[:5000], train_set_Y_full[5000:]\n",
    "test_set_X = test_set_X / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'` color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set_X[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corresponding class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[train_set_Y[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains 55,000 images, validation set has 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1036.8x259.2 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 3\n",
    "n_cols = 12\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(train_set_X[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[train_set_Y[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1a56b1fc940>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a56b1fc630>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a56b1fc128>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a56b3a03c8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flatten'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense\").output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_1\").count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0187 - accuracy: 0.6807 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5028 - accuracy: 0.8260 - val_loss: 0.4345 - val_accuracy: 0.8538\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4485 - accuracy: 0.8423 - val_loss: 0.5341 - val_accuracy: 0.7988\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4211 - accuracy: 0.8529 - val_loss: 0.3915 - val_accuracy: 0.8644\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4062 - accuracy: 0.8580 - val_loss: 0.3748 - val_accuracy: 0.8690\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3756 - accuracy: 0.8671 - val_loss: 0.3707 - val_accuracy: 0.8728\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3655 - accuracy: 0.8709 - val_loss: 0.3623 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3481 - accuracy: 0.8755 - val_loss: 0.3848 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3487 - accuracy: 0.8760 - val_loss: 0.3588 - val_accuracy: 0.8704\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3299 - accuracy: 0.8835 - val_loss: 0.3427 - val_accuracy: 0.8780\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3220 - accuracy: 0.8831 - val_loss: 0.3433 - val_accuracy: 0.8786\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3122 - accuracy: 0.8874 - val_loss: 0.3310 - val_accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3056 - accuracy: 0.8889 - val_loss: 0.3262 - val_accuracy: 0.8888\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2994 - accuracy: 0.8918 - val_loss: 0.3387 - val_accuracy: 0.8774\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2934 - accuracy: 0.8947 - val_loss: 0.3205 - val_accuracy: 0.8864\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2863 - accuracy: 0.8978 - val_loss: 0.3083 - val_accuracy: 0.8908\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2779 - accuracy: 0.9007 - val_loss: 0.3546 - val_accuracy: 0.8740\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2778 - accuracy: 0.8995 - val_loss: 0.3138 - val_accuracy: 0.8902\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2742 - accuracy: 0.9022 - val_loss: 0.3130 - val_accuracy: 0.8898\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2702 - accuracy: 0.9034 - val_loss: 0.3271 - val_accuracy: 0.8804\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2671 - accuracy: 0.9049 - val_loss: 0.3069 - val_accuracy: 0.8918\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9049 - val_loss: 0.2971 - val_accuracy: 0.8960\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2550 - accuracy: 0.9076 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2451 - accuracy: 0.9124 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2497 - accuracy: 0.9108 - val_loss: 0.2970 - val_accuracy: 0.8954\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2433 - accuracy: 0.9131 - val_loss: 0.3055 - val_accuracy: 0.8888\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2375 - accuracy: 0.9162 - val_loss: 0.3019 - val_accuracy: 0.8952\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2317 - accuracy: 0.9174 - val_loss: 0.2993 - val_accuracy: 0.8930\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2284 - accuracy: 0.9174 - val_loss: 0.3052 - val_accuracy: 0.8892\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2256 - accuracy: 0.9203 - val_loss: 0.3032 - val_accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y, epochs=30,\n",
    "                    validation_data=(valid_set_X, valid_set_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33773481845855713, 0.8827000260353088]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_X = test_set_X[:3]\n",
    "predictions = model.predict(samples_X)\n",
    "predictions.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_classes = np.argmax(model.predict(samples_X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot', 'Pullover', 'Trouser']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[class_names[i] for i in predictions_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_Y = test_set_Y[:3]\n",
    "samples_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(samples_X):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[test_set_Y[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will use Scikit-Learns `fetch_california_housing()` function to load the data: this dataset is simpler than the one we used in `End_to_end_machine_learning_project`, since it contains only numerical features (there is no ocean_proximity feature), and there is no missing value.<br>\n",
    "After loading the data, we split it into a training set, a validation set and a test set, and we scale all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "train_set_X_full, test_set_X, train_set_Y_full, test_set_Y = train_test_split(housing.data, housing.target, random_state=42)\n",
    "train_set_X, valid_set_X, train_set_Y, valid_set_Y = train_test_split(train_set_X_full, train_set_Y_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_set_X = scaler.fit_transform(train_set_X)\n",
    "valid_set_X = scaler.transform(valid_set_X)\n",
    "test_set_X = scaler.transform(test_set_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3870, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2656 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7413 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6604 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6245 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5770 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5609 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5500 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5200 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5051 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4794 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4693 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4537 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4586 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4407 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4128 - val_loss: 0.3969\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit(train_set_X, train_set_Y,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_set_X, valid_set_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 830us/step - loss: 0.4212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42117786407470703"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(test_set_X, test_set_Y)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_X = test_set_X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(samples_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a non-sequential neural network is a Wide & Deep neural network. It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers, thus simple patterns in the data may end up being distorted by this sequence of transformations.<br>\n",
    "<b>Note</b>: It's called functional API, because we pass previous layer to the next layer as a parameter, just like functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=[8])\n",
    "hidden_layer_1 = keras.layers.Dense(30, activation=\"relu\")(input_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "concat_layer = keras.layers.concatenate([input_layer, hidden_layer_2])\n",
    "output_layer = keras.layers.Dense(1)(concat_layer)\n",
    "model = keras.models.Model(inputs=[input_layer], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9731 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7638 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6045 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5862 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5243 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5185 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4947 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4782 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4708 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4476 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4361 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4216 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3939 - val_loss: 0.4054\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_set_X, valid_set_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 832us/step - loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4701073],\n",
       "       [1.8735044],\n",
       "       [3.379823 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(samples_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Inputs through Wide path and Deep path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we wanted to send a subset of the features through the wide path, and a\n",
    "different subset (with overlapping) through the deep path. In\n",
    "this case, one solution is to use multiple inputs. For example, suppose we want to\n",
    "send 5 features through the wide path (features 0 to 4), and 6 features through the\n",
    "deep path (features 2 to 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_layer_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_layer_1 = keras.layers.Dense(30, activation=\"relu\")(input_layer_B)\n",
    "hidden_layer_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "concat_layer = keras.layers.concatenate([input_layer_A, hidden_layer_2])\n",
    "output_layer = keras.layers.Dense(1, name=\"output\")(concat_layer)\n",
    "model = keras.models.Model(inputs=[input_layer_A, input_layer_B], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X_A, train_set_X_B = train_set_X[:, :5], train_set_X[:, 2:]\n",
    "valid_set_X_A, valid_set_X_B = valid_set_X[:, :5], valid_set_X[:, 2:]\n",
    "test_set_X_A, test_set_X_B = test_set_X[:, :5], test_set_X[:, 2:]\n",
    "samples_X_A, samples_X_B = test_set_X_A[:3], test_set_X_B[:3]\n",
    "samples_Y = test_set_Y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.1941 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7247 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6176 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5799 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5409 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5173 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5186 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4977 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4765 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4676 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4574 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4479 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4487 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4469 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4495 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4378 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4151 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4204\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((train_set_X_A, train_set_X_B), train_set_Y,\n",
    "                    epochs=20,\n",
    "                    validation_data=((valid_set_X_A, valid_set_X_B), valid_set_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((test_set_X_A, test_set_X_B), test_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30591208],\n",
       "       [1.9540672 ],\n",
       "       [3.442611  ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict((samples_X_A, samples_X_B))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many use cases in which you may want to have multiple outputs:<br><br>\n",
    " The task may demand it, for example you may want to locate and classify the\n",
    "main object in a picture. This is both a regression task (finding the coordinates of\n",
    "the objects center, as well as its width and height) and a classification task.<br>\n",
    " Similarly, you may have multiple independent tasks to perform based on the\n",
    "same data. Sure, you could train one neural network per task, but in many cases\n",
    "you will get better results on all tasks by training a single neural network with\n",
    "one output per task. This is because the neural network can learn features in the\n",
    "data that are useful across tasks.<br>\n",
    " Another use case is as a regularization technique (i.e., a training constraint whose\n",
    "objective is to reduce overfitting and thus improve the models ability to generalize).\n",
    "For example, you may want to add some auxiliary outputs in a neural network\n",
    "architecture to ensure that the underlying part of the\n",
    "network learns something useful on its own, without relying on the rest of the\n",
    "network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_layer_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_layer_1 = keras.layers.Dense(30, activation=\"relu\")(input_layer_B)\n",
    "hidden_layer_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "concat_layer = keras.layers.concatenate([input_layer_A, hidden_layer_2])\n",
    "output_layer = keras.layers.Dense(1, name=\"output\")(concat_layer)\n",
    "auxiliary_output_layer = keras.layers.Dense(1, name=\"auxiliary_output\")(hidden_layer_2)\n",
    "model = keras.models.Model(inputs=[input_layer_A, input_layer_B], outputs=[output_layer, auxiliary_output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output will need its own loss function, so when we compile the model we\n",
    "should pass a list of losses (if we pass a single loss, Keras will assume that the same\n",
    "loss must be used for all outputs). By default, Keras will compute all these losses and\n",
    "simply add them up to get the final loss used for training. However, we care much\n",
    "more about the main output than about the auxiliary output (as it is just used for regularization),\n",
    "so we want to give the main outputs loss a much greater weight. Fortunately,\n",
    "it is possible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"],\n",
    "              loss_weights=[0.9, 0.1],\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.4633 - output_loss: 3.3289 - auxiliary_output_loss: 4.6732 - val_loss: 1.6233 - val_output_loss: 0.8468 - val_auxiliary_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9807 - output_loss: 0.7503 - auxiliary_output_loss: 3.0537 - val_loss: 1.5163 - val_output_loss: 0.6836 - val_auxiliary_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7742 - output_loss: 0.6290 - auxiliary_output_loss: 2.0810 - val_loss: 1.4639 - val_output_loss: 0.6229 - val_auxiliary_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6952 - output_loss: 0.5897 - auxiliary_output_loss: 1.6449 - val_loss: 1.3388 - val_output_loss: 0.5481 - val_auxiliary_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6469 - output_loss: 0.5508 - auxiliary_output_loss: 1.5118 - val_loss: 1.2177 - val_output_loss: 0.5194 - val_auxiliary_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6120 - output_loss: 0.5251 - auxiliary_output_loss: 1.3943 - val_loss: 1.0935 - val_output_loss: 0.5106 - val_auxiliary_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6114 - output_loss: 0.5256 - auxiliary_output_loss: 1.3833 - val_loss: 0.9918 - val_output_loss: 0.5115 - val_auxiliary_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5765 - output_loss: 0.5024 - auxiliary_output_loss: 1.2439 - val_loss: 0.8733 - val_output_loss: 0.4733 - val_auxiliary_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5535 - output_loss: 0.4811 - auxiliary_output_loss: 1.2057 - val_loss: 0.7832 - val_output_loss: 0.4555 - val_auxiliary_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - output_loss: 0.4708 - auxiliary_output_loss: 1.2189 - val_loss: 0.7170 - val_output_loss: 0.4604 - val_auxiliary_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5297 - output_loss: 0.4587 - auxiliary_output_loss: 1.1684 - val_loss: 0.6510 - val_output_loss: 0.4293 - val_auxiliary_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5181 - output_loss: 0.4501 - auxiliary_output_loss: 1.1305 - val_loss: 0.6051 - val_output_loss: 0.4310 - val_auxiliary_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5100 - output_loss: 0.4487 - auxiliary_output_loss: 1.0620 - val_loss: 0.5644 - val_output_loss: 0.4161 - val_auxiliary_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5064 - output_loss: 0.4459 - auxiliary_output_loss: 1.0503 - val_loss: 0.5354 - val_output_loss: 0.4119 - val_auxiliary_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5027 - output_loss: 0.4452 - auxiliary_output_loss: 1.0207 - val_loss: 0.5124 - val_output_loss: 0.4047 - val_auxiliary_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5057 - output_loss: 0.4480 - auxiliary_output_loss: 1.0249 - val_loss: 0.4934 - val_output_loss: 0.4034 - val_auxiliary_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4931 - output_loss: 0.4360 - auxiliary_output_loss: 1.0075 - val_loss: 0.4801 - val_output_loss: 0.3984 - val_auxiliary_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4922 - output_loss: 0.4352 - auxiliary_output_loss: 1.0053 - val_loss: 0.4694 - val_output_loss: 0.3962 - val_auxiliary_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4658 - output_loss: 0.4139 - auxiliary_output_loss: 0.9323 - val_loss: 0.4580 - val_output_loss: 0.3936 - val_auxiliary_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4589 - output_loss: 0.4072 - auxiliary_output_loss: 0.9243 - val_loss: 0.4655 - val_output_loss: 0.4048 - val_auxiliary_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_set_X_A, train_set_X_B], [train_set_Y, train_set_Y],\n",
    "                    epochs=20,\n",
    "                    validation_data=([valid_set_X_A, valid_set_X_B], [valid_set_Y, valid_set_Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4668 - output_loss: 0.4178 - auxiliary_output_loss: 0.9082\n"
     ]
    }
   ],
   "source": [
    "total_loss, output_loss, aux_loss = model.evaluate((test_set_X_A, test_set_X_B), (test_set_Y, test_set_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A56B065EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "output_predictions, aux_predictions = model.predict((samples_X_A, samples_X_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26762432],\n",
       "       [1.9807628 ],\n",
       "       [3.3396287 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9593649],\n",
       "       [1.9240992],\n",
       "       [2.5152814]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A5509466A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "output_predictions, aux_predictions = model.predict((samples_X_A, samples_X_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26762432],\n",
       "       [1.9807628 ],\n",
       "       [3.3396287 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9593649],\n",
       "       [1.9240992],\n",
       "       [2.5152814]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a550a49208>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Callbacks during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch. Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the ModelCheckpoint. In this case, it will only save your model when its performance on the validation set is the best so far. This\n",
    "way, you do not need to worry about training for too long and overfitting the training set. Simply restore the last model saved after training, and this will be the best model on the validation set. This is a simple way to implement <b>early stopping</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4396\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4295 - val_loss: 0.4507\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.3997\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.3956\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4198 - val_loss: 0.3916\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4248 - val_loss: 0.3937\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.3809\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.3793\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.3850\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3864 - val_loss: 0.3809\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_set_X, valid_set_Y),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4003\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement <b>early stopping</b> is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the patience argument), and it will optionally roll back to the best model. You can combine both callbacks to both save checkpoints of your model (in case your computer crashes), and actually interrupt training early when there is no more progress (to avoid wasting time and resources). Besides, The number of epochs can be set to a large value since training will stop automatically when there is no more progress. Moreover, there is no need to restore the best model saved in this case since the EarlyStopping callback will keep track of the best weights and restore them for us at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4006 - val_loss: 0.3751\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.3728\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.3691\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.3677\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3648\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.3625\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3604\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3830 - val_loss: 0.3593\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3579\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.3549\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.3525\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.3556\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3534\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.3485\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3610\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3467\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3673 - val_loss: 0.3589\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3525\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3463\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3829\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3545\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3829\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3603 - val_loss: 0.3393\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3572\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3537\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3663\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3564 - val_loss: 0.3355\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3554 - val_loss: 0.3590\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3444\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3623\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3373\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3763\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3519 - val_loss: 0.3313\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3359\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3586\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3302\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3490 - val_loss: 0.3551\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3314\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3387\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3328\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3493\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3462 - val_loss: 0.3393\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3668\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3534\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3302\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3436 - val_loss: 0.3425\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y,\n",
    "                    epochs=100,\n",
    "                    validation_data=(valid_set_X, valid_set_Y),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3488\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need extra control, you can easily write your own custom callbacks. For example, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3644\n",
      "\n",
      "val/train: 1.04\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(train_set_X, train_set_Y,\n",
    "                    epochs=1,\n",
    "                    validation_data=(valid_set_X, valid_set_Y),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by\n",
    "your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more.<br>\n",
    "To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called `event files`. Each binary data record is called a summary. The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations. this allows you to visualize live data (with a short delay), such as the learning curves during training. In general, you want to point the TensorBoard server to a root log directory, and configure your program so that it writes to a different subdirectory every time it runs. This way, the same TensorBoard server instance will allow you to visualize and compare data from multiple runs of your program, without getting everything mixed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_log_dir = os.path.join(os.curdir, \"my_logs\")\n",
    "root_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_06_13-12_34_27'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_log_dir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_log_dir, run_id)\n",
    "\n",
    "run_log_dir = get_run_log_dir()\n",
    "run_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4326 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4207 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4198 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4248 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3839 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3736 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y, epochs=30,\n",
    "                    validation_data=(valid_set_X, valid_set_Y),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, go to this notebook's directory (`C:\\Users\\Behzad\\Desktop\\Git-Projects\\Machine-Learning - master\\Neural Networks`), then type:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
    "\n",
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this (uncomment first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By openning TensorBoard, you can see the history of the run you just have saved in the `my_logs` folder, and compare the learning rates of its loss and val_loss.<br>\n",
    "Now let's try the same model with different learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_06_13-12_34_49'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_log_dir_2 = get_run_log_dir()\n",
    "run_log_dir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7645 - val_loss: 302.8536\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 8159520618.2209 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3439 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3546 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3513 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3274 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3639 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3487 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3445 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3697 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3622 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3389 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3336 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3275 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3669 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3645 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3839 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3078 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3215 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3344 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3269 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3590 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3265 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3532 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3552 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3447 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3379 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3583 - val_loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y, epochs=30,\n",
    "                    validation_data=(valid_set_X, valid_set_Y),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves of all the saved runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flexibility of neural networks is also one of their main drawbacks. There are many hyperparameters to tweak.\n",
    "Not only can you use any imaginable network architecture, but even in a simple MLP you can change the number of layers,\n",
    "the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic,\n",
    "and much more. How do you know what combination of hyperparameters is the best for your task?\n",
    "\n",
    "One option is to simply try many combinations of hyperparameters and see which one works best on the validation set (or using K-fold cross-validation). For this, one approach is simply use GridSearchCV or RandomizedSearchCV to explore the hyperparameter\n",
    "space. For this, we need to wrap our Keras models in objects that mimic regular Scikit-Learn regressors. The first step is to create a function that will build and compile a Keras model, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    \"\"\"Input Layer\"\"\"\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \"\"\"Hidden Layers\"\"\"\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    \"\"\"Output Layer\"\"\"\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,231\n",
      "Trainable params: 1,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_regressor_model = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KerasRegressor object is a thin wrapper around the Keras model built using build_model(). Since we did not specify any hyperparameter when creating it, it will just use the default hyperparameters we defined in build_model(). Now we can use\n",
    "this object like a regular Scikit-Learn regressor. We can train it using its fit() method, then evaluate it using its score() method, and use it to make predictions using its predict() method. Note that any extra parameter you pass to the fit()\n",
    "method will simply get passed to the underlying Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9281 - val_loss: 1.7696\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6750 - val_loss: 0.5361\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5481 - val_loss: 0.5093\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.4392\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4161\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4036\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.3930\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.3925\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.3853\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.3835\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3895\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3993 - val_loss: 0.3862\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3989\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3874\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3781\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3754\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3839 - val_loss: 0.3953\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3752 - val_loss: 0.3856\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.4188\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3913\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3640 - val_loss: 0.4175\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3939 - val_loss: 0.3698\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.3932\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4069\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.4034\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.3677\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.4000\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3668 - val_loss: 0.3803\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4083\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.3743\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4083\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3661 - val_loss: 0.3732\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3840\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3526 - val_loss: 0.4044\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3549\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3796 - val_loss: 0.3838\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.3637\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.3606\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3765\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.3957\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.4018\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3826\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3986\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3525\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3485\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3852\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3813\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3635 - val_loss: 0.3598\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3408\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 0.4100\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3343\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.4641\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3390\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3492 - val_loss: 0.3613\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3383\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3427 - val_loss: 0.3304\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.4402\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3700\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3538\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3503\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3938\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3307\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3567\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3514\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3370 - val_loss: 0.3267\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3413\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3718\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.4790\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3763\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3227 - val_loss: 0.3852\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3384 - val_loss: 0.3637\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.5490\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3286 - val_loss: 0.3623\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3848\n"
     ]
    }
   ],
   "source": [
    "history = keras_regressor_model.fit(train_set_X, train_set_Y,\n",
    "              epochs=100,\n",
    "              validation_data=(valid_set_X, valid_set_Y),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that the score will be the opposite of the MSE because Scikit-Learn wants scores, not losses (i.e., higher should be better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3421\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_regressor_model.score(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A550923400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6161098, 1.6638539, 4.221405 ], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = keras_regressor_model.predict(samples_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6440 - val_loss: 1.7879\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1258 - val_loss: 0.9685\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7961 - val_loss: 0.6780\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.5945\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.5620\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5736 - val_loss: 0.5342\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.5106\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.4928\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.4787\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.4619\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.4526\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4445\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.4356\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4402\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4350 - val_loss: 0.4316\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.4343\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4353\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4297\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4343\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.4251\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4347\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4248\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4215\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.4103\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4185\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4069\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4084\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4095\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.4085\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.3964\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.3894\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.3898\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3932\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.3881\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3841\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3890\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3777\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.3918\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3745\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3872\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3866\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3789\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3735\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.3848\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3786\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3768\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3790\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3505 - val_loss: 0.3812\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3701\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3785\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3797\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3765\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3755\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3552 - val_loss: 0.3695\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.3749\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.3701\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3773\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3594 - val_loss: 0.3756\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.3708\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3691\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.3691\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3873\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.3719\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 0.3731\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3777\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3731\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.3715\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3754\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3662\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3679\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3715\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3638\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3623\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3681\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3626\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3662\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.3596\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.3685\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3625\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3310 - val_loss: 0.3648\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3655\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3650\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3629\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3571\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3624\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.3524\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3587\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3525\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.3583\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3531\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.3535\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.3568\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3448\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 0.3525\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3510\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3416\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3479\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3688\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3490\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3557\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=26; total time=  46.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2941 - val_loss: 18.1232\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8584 - val_loss: 15.5662\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7289 - val_loss: 11.5693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6670 - val_loss: 8.7731\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 6.5788\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 4.7616\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 3.2558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 2.3595\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4968 - val_loss: 1.8807\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 1.5338\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 1.2843\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4342 - val_loss: 1.0573\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.9371\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.9365\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.8505\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.8767\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4141 - val_loss: 0.8453\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4195 - val_loss: 0.8752\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.8599\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.8695\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.8908\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.9335\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.9939\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.9871\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 1.0068\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 1.0512\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 1.0974\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3922\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=26; total time=  13.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3305 - val_loss: 3.0844\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0619 - val_loss: 1.5801\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7688 - val_loss: 1.0671\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7034 - val_loss: 0.8300\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6418 - val_loss: 0.7400\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6085 - val_loss: 0.6908\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.6564\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5830 - val_loss: 0.6240\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5664 - val_loss: 0.5987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5758\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.5591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4966 - val_loss: 0.5386\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 0.5204\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.5075\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.4930\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.4765\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.4666\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4455 - val_loss: 0.4578\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4500\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.4482\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.4415\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4332 - val_loss: 0.4395\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.4367\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4391\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4311\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4286\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.4305\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.4279\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4316\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.4250\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4250\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4229\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4201\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.4260\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4217\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4169\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.4172\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4143\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.4149\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3747 - val_loss: 0.4106\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4128\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4101\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4038\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4023\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4038\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.4027\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3983\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.3974\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.4003\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3606 - val_loss: 0.3994\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3969\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.3994\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3615 - val_loss: 0.4000\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.3939\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.3975\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3994\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 0.3993\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3984\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3952\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3938\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3899\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3574 - val_loss: 0.3916\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3868\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3868\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.3858\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.3880\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3854\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.3873\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3858\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3865\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.3854\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3869\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3883\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3913\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3383 - val_loss: 0.3962\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3999\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.4002\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.4074\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4148\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3408 - val_loss: 0.4064\n",
      "121/121 [==============================] - 0s 806us/step - loss: 0.3444\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=26; total time=  41.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.1180 - val_loss: 4.5900\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8497 - val_loss: 4.6231\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9550 - val_loss: 4.8846\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3329 - val_loss: 5.0398\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8805 - val_loss: 4.9670\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6321 - val_loss: 4.7885\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4776 - val_loss: 4.3993\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3214 - val_loss: 3.8958\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1757 - val_loss: 3.3951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0988 - val_loss: 2.9438\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9918 - val_loss: 2.5751\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 2.2519\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9139 - val_loss: 1.9906\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8522 - val_loss: 1.7642\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8132 - val_loss: 1.5648\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7615 - val_loss: 1.3948\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7610 - val_loss: 1.2548\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7185 - val_loss: 1.1367\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7070 - val_loss: 1.0419\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6949 - val_loss: 0.9608\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6711 - val_loss: 0.8958\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 0.8418\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6667 - val_loss: 0.7982\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.7598\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6456 - val_loss: 0.7299\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.7043\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 0.6823\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6362 - val_loss: 0.6642\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6399 - val_loss: 0.6491\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6136 - val_loss: 0.6349\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5857 - val_loss: 0.6226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5903 - val_loss: 0.6127\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5902 - val_loss: 0.6040\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5915 - val_loss: 0.5964\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5864 - val_loss: 0.5898\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5677 - val_loss: 0.5831\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5890 - val_loss: 0.5780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.5721\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5799 - val_loss: 0.5675\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - val_loss: 0.5632\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - val_loss: 0.5591\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5733 - val_loss: 0.5551\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 0.5512\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 0.5478\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 0.5444\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.5407\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.5375\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.5346\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.5317\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.5287\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.5258\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5534 - val_loss: 0.5231\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5206\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.5181\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.5157\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 0.5134\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5109\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.5088\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.5066\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5042\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.5020\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.4977\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5110 - val_loss: 0.4958\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4898 - val_loss: 0.4939\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.4919\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.4899\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.4881\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.4863\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5192 - val_loss: 0.4843\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.4825\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.4809\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.4792\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.4776\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.4760\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.4743\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.4729\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.4714\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.4698\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.4682\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.4668\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4657\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.4643\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.4631\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.4615\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4605\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4745 - val_loss: 0.4593\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4712 - val_loss: 0.4579\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.4565\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4553 - val_loss: 0.4554\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.4541\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4778 - val_loss: 0.4530\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.4517\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.4505\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4497\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4489\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.4479\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4563 - val_loss: 0.4466\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4460\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.4449\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4694\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=2, n_neurons=59; total time=  44.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.1763 - val_loss: 8.3300\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.4910 - val_loss: 13.5364\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4820 - val_loss: 18.9779\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9089 - val_loss: 23.4322\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5340 - val_loss: 26.2319\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3248 - val_loss: 27.6538\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2223 - val_loss: 28.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1132 - val_loss: 27.5585\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0909 - val_loss: 26.6800\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 25.5032\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9672 - val_loss: 24.2381\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4563\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=2, n_neurons=59; total time=   6.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.6188 - val_loss: 4.1579\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9978 - val_loss: 3.7260\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9332 - val_loss: 4.0073\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3066 - val_loss: 4.4764\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7348 - val_loss: 4.4897\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4159 - val_loss: 4.2794\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1704 - val_loss: 3.8958\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1206 - val_loss: 3.3881\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9953 - val_loss: 2.8450\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8842 - val_loss: 2.3506\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8905 - val_loss: 1.9660\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7927 - val_loss: 1.6112\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7259 - val_loss: 1.3380\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7186 - val_loss: 1.1323\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7310 - val_loss: 0.9770\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7120 - val_loss: 0.8640\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6825 - val_loss: 0.7829\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 0.7246\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6721 - val_loss: 0.6855\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6560 - val_loss: 0.6601\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6411 - val_loss: 0.6415\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6764 - val_loss: 0.6274\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6339 - val_loss: 0.6171\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6325 - val_loss: 0.6094\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.6030\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.5977\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.5932\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6277 - val_loss: 0.5894\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6145 - val_loss: 0.5860\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.5828\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5936 - val_loss: 0.5799\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6252 - val_loss: 0.5770\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6145 - val_loss: 0.5743\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.5715\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5839 - val_loss: 0.5689\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.5658\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5902 - val_loss: 0.5628\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5851 - val_loss: 0.5603\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.5576\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 0.5549\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5520\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5562 - val_loss: 0.5492\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5634 - val_loss: 0.5467\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5755 - val_loss: 0.5440\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - val_loss: 0.5416\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 0.5393\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5721 - val_loss: 0.5362\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.5336\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5611 - val_loss: 0.5312\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5355 - val_loss: 0.5287\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5654 - val_loss: 0.5264\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 0.5239\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5427 - val_loss: 0.5213\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5423 - val_loss: 0.5186\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.5160\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.5132\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.5112\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.5089\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5331 - val_loss: 0.5067\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5425 - val_loss: 0.5049\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.5020\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5175 - val_loss: 0.4997\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.4975\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.4953\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.4929\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.4905\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.4888\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.4867\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4843\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.4826\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 0.4808\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4789\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5039 - val_loss: 0.4770\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.4746\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.4724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5119 - val_loss: 0.4704\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4932 - val_loss: 0.4686\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.4670\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4927 - val_loss: 0.4648\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4768 - val_loss: 0.4628\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4742 - val_loss: 0.4610\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4892 - val_loss: 0.4593\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.4576\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4908 - val_loss: 0.4559\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.4541\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4663 - val_loss: 0.4525\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.4508\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 0.4493\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.4475\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.4460\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4766 - val_loss: 0.4446\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4430\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4530 - val_loss: 0.4416\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.4401\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.4386\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.4372\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.4359\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.4345\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.4333\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4320\n",
      "121/121 [==============================] - 0s 795us/step - loss: 0.4613\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=2, n_neurons=59; total time=  48.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.6045 - val_loss: 3.1840\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3138 - val_loss: 1.4140\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3259 - val_loss: 1.0936\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9466 - val_loss: 0.9893\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7771 - val_loss: 0.9346\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 1.0185\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7000 - val_loss: 1.0098\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6640 - val_loss: 1.0024\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6517 - val_loss: 0.8787\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6506 - val_loss: 0.9410\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 0.9637\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 0.8227\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6452 - val_loss: 0.9247\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6245 - val_loss: 0.9829\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6256 - val_loss: 0.8552\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5955 - val_loss: 0.8834\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6262 - val_loss: 0.8962\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.9320\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5937 - val_loss: 0.9513\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.9440\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.8068\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - val_loss: 0.8596\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5869 - val_loss: 0.8690\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - val_loss: 0.8624\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5801 - val_loss: 0.8050\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5518 - val_loss: 0.7177\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5771 - val_loss: 0.8369\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5706 - val_loss: 0.7218\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5767 - val_loss: 0.7792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5600 - val_loss: 0.7454\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5451 - val_loss: 0.7276\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 0.6784\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5424 - val_loss: 0.7304\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5443 - val_loss: 0.7367\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.6554\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5343 - val_loss: 0.7446\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5939\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.7351\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5369 - val_loss: 0.6618\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.6798\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5358 - val_loss: 0.7445\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5390 - val_loss: 0.6501\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.6154\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.7217\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.7162\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.6602\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 0.7228\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5420\n",
      "[CV] END ......learning_rate=0.001, n_hidden=0, n_neurons=60; total time=  19.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9878 - val_loss: 6.9730\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1040 - val_loss: 6.6753\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1507 - val_loss: 7.2792\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8162 - val_loss: 8.1367\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6708 - val_loss: 9.0712\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6107 - val_loss: 10.0116\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5904 - val_loss: 10.9103\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5771 - val_loss: 11.7856\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5714 - val_loss: 12.6011\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5554 - val_loss: 13.3206\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5568 - val_loss: 14.0559\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5426 - val_loss: 14.7395\n",
      "121/121 [==============================] - 0s 768us/step - loss: 0.8977\n",
      "[CV] END ......learning_rate=0.001, n_hidden=0, n_neurons=60; total time=   6.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.9799 - val_loss: 4.9077\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0292 - val_loss: 1.8819\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6190 - val_loss: 1.1244\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1055 - val_loss: 0.9566\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8652 - val_loss: 0.8262\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7673 - val_loss: 0.8244\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7183 - val_loss: 0.8440\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7208 - val_loss: 0.9498\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.9005\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6587 - val_loss: 0.7821\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6782 - val_loss: 0.9112\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6398 - val_loss: 0.8319\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.7571\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.7992\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.7555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.8552\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.7901\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6227 - val_loss: 0.7510\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6149 - val_loss: 0.8751\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5911 - val_loss: 0.8168\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5852 - val_loss: 0.7914\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.7949\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5829 - val_loss: 0.7111\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5717 - val_loss: 0.7165\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - val_loss: 0.7028\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - val_loss: 0.6480\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5867 - val_loss: 0.8004\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - val_loss: 0.7513\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.8136\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - val_loss: 0.7625\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5468 - val_loss: 0.7812\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 0.8211\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.8311\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.8550\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5417 - val_loss: 0.8572\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5505 - val_loss: 0.7042\n",
      "121/121 [==============================] - 0s 772us/step - loss: 0.5507\n",
      "[CV] END ......learning_rate=0.001, n_hidden=0, n_neurons=60; total time=  14.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.3323 - val_loss: 12.9704\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.9224 - val_loss: 11.7113\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.5853 - val_loss: 10.5924\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.1807 - val_loss: 9.5953\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8103 - val_loss: 8.7063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.6303 - val_loss: 7.9169\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.3957 - val_loss: 7.2117\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1712 - val_loss: 6.5810\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.8840 - val_loss: 6.0137\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6500 - val_loss: 5.5096\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4915 - val_loss: 5.0591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2286 - val_loss: 4.6518\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2590 - val_loss: 4.2906\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0851 - val_loss: 3.9670\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9110 - val_loss: 3.6728\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7767 - val_loss: 3.4104\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7101 - val_loss: 3.1747\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6360 - val_loss: 2.9632\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5273 - val_loss: 2.7727\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4706 - val_loss: 2.6009\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3372 - val_loss: 2.4434\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2950 - val_loss: 2.3033\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2541 - val_loss: 2.1768\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2052 - val_loss: 2.0625\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1496 - val_loss: 1.9580\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0806 - val_loss: 1.8623\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0956 - val_loss: 1.7784\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0196 - val_loss: 1.6997\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 1.6300\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9564 - val_loss: 1.5660\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9122 - val_loss: 1.5078\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8591 - val_loss: 1.4542\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8594 - val_loss: 1.4069\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8357 - val_loss: 1.3635\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8159 - val_loss: 1.3228\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7997 - val_loss: 1.2877\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7804 - val_loss: 1.2441\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7581 - val_loss: 1.2163\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7566 - val_loss: 1.1888\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7094 - val_loss: 1.1646\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7233 - val_loss: 1.1433\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7333 - val_loss: 1.1222\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7104 - val_loss: 1.1029\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 1.0871\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6891 - val_loss: 1.0721\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7024 - val_loss: 1.0576\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6941 - val_loss: 1.0455\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6541 - val_loss: 1.0343\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6665 - val_loss: 1.0242\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7013 - val_loss: 1.0159\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6513 - val_loss: 1.0074\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6940 - val_loss: 0.9992\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6592 - val_loss: 0.9920\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6476 - val_loss: 0.9846\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.9796\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6821 - val_loss: 0.9733\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.9688\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 0.9646\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.9598\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.9550\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6118 - val_loss: 0.9519\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6266 - val_loss: 0.9494\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 0.9470\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6308 - val_loss: 0.9446\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5944 - val_loss: 0.9429\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6501 - val_loss: 0.9411\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6312 - val_loss: 0.9397\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6212 - val_loss: 0.9366\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6400 - val_loss: 0.9359\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6424 - val_loss: 0.9348\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6348 - val_loss: 0.9343\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6402 - val_loss: 0.9332\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6315 - val_loss: 0.9322\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6225 - val_loss: 0.9319\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6236 - val_loss: 0.9310\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.9309\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5894 - val_loss: 0.9288\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.9287\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.9285\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.9274\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5795 - val_loss: 0.9277\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5851 - val_loss: 0.9264\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.9245\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.9236\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.9232\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.9231\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.9214\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5903 - val_loss: 0.9201\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5931 - val_loss: 0.9204\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 0.9208\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.9210\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.9196\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.9205\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5944 - val_loss: 0.9211\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.9199\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5925 - val_loss: 0.9185\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.9173\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5905 - val_loss: 0.9163\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5873 - val_loss: 0.9162\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.9151\n",
      "121/121 [==============================] - 0s 749us/step - loss: 0.6021\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=94; total time=  41.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 8.6110 - val_loss: 7.4277\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8.6057 - val_loss: 6.7170\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6740 - val_loss: 6.1068\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.5639 - val_loss: 5.5835\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.2990 - val_loss: 5.1366\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.7414 - val_loss: 4.7564\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3205 - val_loss: 4.4343\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1193 - val_loss: 4.1636\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.6822 - val_loss: 3.9376\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3805 - val_loss: 3.7505\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.0409 - val_loss: 3.5985\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7776 - val_loss: 3.4768\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4962 - val_loss: 3.3820\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2700 - val_loss: 3.3106\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2882 - val_loss: 3.2602\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9654 - val_loss: 3.2281\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8549 - val_loss: 3.2125\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7254 - val_loss: 3.2112\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5528 - val_loss: 3.2230\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4282 - val_loss: 3.2461\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3699 - val_loss: 3.2794\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3051 - val_loss: 3.3215\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2398 - val_loss: 3.3718\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1527 - val_loss: 3.4289\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0864 - val_loss: 3.4924\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 3.5614\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0118 - val_loss: 3.6355\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 3.7140\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9836\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=94; total time=  12.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 8.0352 - val_loss: 13.5747\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.0629 - val_loss: 11.6287\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.2358 - val_loss: 9.9825\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.8920 - val_loss: 8.5790\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.2243 - val_loss: 7.4006\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6547 - val_loss: 6.3969\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.0398 - val_loss: 5.5439\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.9651 - val_loss: 4.8175\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5431 - val_loss: 4.2052\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2322 - val_loss: 3.6890\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9831 - val_loss: 3.2463\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7582 - val_loss: 2.8742\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4047 - val_loss: 2.5591\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2667 - val_loss: 2.2904\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1388 - val_loss: 2.0636\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9282 - val_loss: 1.8698\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8265 - val_loss: 1.7067\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7270 - val_loss: 1.5686\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5705 - val_loss: 1.4511\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4785 - val_loss: 1.3523\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3677 - val_loss: 1.2689\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3482 - val_loss: 1.1986\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2581 - val_loss: 1.1392\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1603 - val_loss: 1.0894\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1232 - val_loss: 1.0475\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0710 - val_loss: 1.0120\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0397 - val_loss: 0.9833\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0020 - val_loss: 0.9590\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9393\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9228\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8659 - val_loss: 0.9096\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8790 - val_loss: 0.8991\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8434 - val_loss: 0.8908\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7786 - val_loss: 0.8845\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7816 - val_loss: 0.8797\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7684 - val_loss: 0.8746\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7562 - val_loss: 0.8703\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7595 - val_loss: 0.8686\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7466 - val_loss: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7036 - val_loss: 0.8657\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6778 - val_loss: 0.8661\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 0.8660\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6947 - val_loss: 0.8654\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6740 - val_loss: 0.8664\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6604 - val_loss: 0.8680\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6527 - val_loss: 0.8695\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6576 - val_loss: 0.8691\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6287 - val_loss: 0.8701\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6510 - val_loss: 0.8719\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.8734\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6660 - val_loss: 0.8749\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8770\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.8775\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6314\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=94; total time=  20.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.9349 - val_loss: 1.4558\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1265 - val_loss: 0.8157\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8045 - val_loss: 0.6823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6954 - val_loss: 0.6090\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.5704\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 0.5430\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 0.5207\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5020\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.4915\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5016 - val_loss: 0.4712\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4707 - val_loss: 0.4586\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 0.4487\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.4346\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4314\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.4211\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.4167\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.4169\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4119\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4094\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.4033\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4196\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4012\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3963\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.3826\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.3924\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3851\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.3864\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3994\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.3852\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3774\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3665\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3690\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3696\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.3658\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.3791\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.3508\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3884\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3502\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.3657\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.3624\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3554 - val_loss: 0.3506\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3500\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.3745\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3552\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 0.3549\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.3624\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.3496\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.3432\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3663\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.3547\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.3466\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3483\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3398\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3514\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.3410\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3526\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.3461\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3386\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3431\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.3418\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3664\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3410\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3508\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3200 - val_loss: 0.3603\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3350\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.3470\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3430\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3378\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3365\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3420\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.3331\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3328\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3397\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3325\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3429\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3241 - val_loss: 0.3296\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.3487\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3334\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3267 - val_loss: 0.3371\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3377\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3158 - val_loss: 0.3337\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3304\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3335\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3292\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.3295\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3193 - val_loss: 0.3260\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3332\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3229 - val_loss: 0.3264\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3425\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3275\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3339\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.3282\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3258\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3315\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3207 - val_loss: 0.3249\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3253 - val_loss: 0.3237\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3234\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.3532\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3233\n",
      "121/121 [==============================] - 0s 794us/step - loss: 0.3532\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=30; total time=  47.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0115 - val_loss: 19.2945\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8902 - val_loss: 6.8512\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7213 - val_loss: 1.8048\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6636 - val_loss: 0.6049\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6255 - val_loss: 0.8762\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 1.4904\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5516 - val_loss: 2.1698\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 2.8340\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 2.9757\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 2.8714\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4839 - val_loss: 3.0984\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 3.1729\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 3.0509\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 2.1474\n",
      "121/121 [==============================] - 0s 959us/step - loss: 0.5015\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=30; total time=   6.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5395 - val_loss: 3.4816\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0239 - val_loss: 2.0219\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7396 - val_loss: 1.1753\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6786 - val_loss: 0.8385\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.6984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 0.6153\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5813 - val_loss: 0.5759\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5735 - val_loss: 0.5350\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.5139\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.4965\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.4822\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 0.4714\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4713 - val_loss: 0.4615\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4747 - val_loss: 0.4522\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.4430\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.4341\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4466 - val_loss: 0.4267\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4652 - val_loss: 0.4214\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4555 - val_loss: 0.4138\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4406 - val_loss: 0.4077\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4024\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.3982\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.3941\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.3931\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.3888\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.3891\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.3861\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.3871\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3905\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.3857\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3865\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.3900\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.3871\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.3966\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.3899\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.3888\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3940 - val_loss: 0.3908\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3932\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.3968\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.3949\n",
      "121/121 [==============================] - 0s 819us/step - loss: 0.3890\n",
      "[CV] END ......learning_rate=0.001, n_hidden=3, n_neurons=30; total time=  20.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7780 - val_loss: 1.2270\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8993 - val_loss: 0.7052\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.6212\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6420 - val_loss: 0.5765\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6038 - val_loss: 0.5452\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5613 - val_loss: 0.5227\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - val_loss: 0.5060\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.4772\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.4709\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.4461\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.4350\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4319 - val_loss: 0.4304\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4148\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4405 - val_loss: 0.4174\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4362 - val_loss: 0.4195\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4067\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4348 - val_loss: 0.4208\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 0.4029\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.4074\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.4037\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4255\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4018\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4097\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.3872\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4154\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.3899\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.4112\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4082\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4204\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 0.3869\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3794\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3974\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3972\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3645\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4049\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.3551\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.4228\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.3635\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3999\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3851\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3613\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.3625\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.4155\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3716\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.3754\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3970\n",
      "121/121 [==============================] - 0s 881us/step - loss: 0.3728\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=95; total time=  21.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6853 - val_loss: 10.6153\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 7.1899\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7295 - val_loss: 4.2079\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6754 - val_loss: 2.3425\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6356 - val_loss: 1.3329\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5915 - val_loss: 0.8289\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5665 - val_loss: 0.5792\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5349 - val_loss: 0.4993\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5216\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5021 - val_loss: 0.6002\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.6838\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.8082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.8899\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.8385\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.8818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.8716\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 0.8329\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.7878\n",
      "121/121 [==============================] - 0s 864us/step - loss: 0.4439\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=95; total time=   8.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.9761 - val_loss: 1.0202\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8862 - val_loss: 0.6770\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6588 - val_loss: 0.6004\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.5568\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5631 - val_loss: 0.5298\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5266 - val_loss: 0.5002\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5089 - val_loss: 0.4762\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5001 - val_loss: 0.4549\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4504\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4471 - val_loss: 0.4363\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4549 - val_loss: 0.4307\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4275 - val_loss: 0.4238\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.4317\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.4081\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4160\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.3956\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.3899\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4057\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4007\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3930 - val_loss: 0.3995\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.3929\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.3843\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4153\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3836\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3780\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4165\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3899\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4260\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.3968\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3940\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4207\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.4090\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.4285\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3943\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.3856\n",
      "121/121 [==============================] - 0s 877us/step - loss: 0.3670\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=95; total time=  18.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7568 - val_loss: 1.3570\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8449 - val_loss: 0.8490\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7373 - val_loss: 0.7262\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.6689\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.6256\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5922 - val_loss: 0.5964\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5739 - val_loss: 0.5556\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 0.5385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5322\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5008\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.4909\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4333 - val_loss: 0.4855\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4426 - val_loss: 0.4829\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4342 - val_loss: 0.4814\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 0.4719\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.4874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4813\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4907\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4860\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.5135\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4987\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4975\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4097\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=44; total time=  11.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6770 - val_loss: 9.5812\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8571 - val_loss: 5.8579\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 3.2001\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 1.8965\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.1845\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5045 - val_loss: 0.8148\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.6066\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.4921\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.4477\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4209\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4107\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.4051\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4194 - val_loss: 0.4012\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.3973\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.3920\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3890\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.3852\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.3843\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3825\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.3835\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.3825\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.3858\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.3937\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3977\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4069\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4190\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4258\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.4422\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4769\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.4749\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4697\n",
      "121/121 [==============================] - 0s 781us/step - loss: 0.3897\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=44; total time=  14.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3798 - val_loss: 2.7984\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9829 - val_loss: 1.8737\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7549 - val_loss: 1.0733\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7034 - val_loss: 0.7754\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6578 - val_loss: 0.6636\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.6112\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.5886\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.5612\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5891 - val_loss: 0.5453\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 0.5310\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5560 - val_loss: 0.5159\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5025\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.4916\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.4851\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5151 - val_loss: 0.4758\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4949 - val_loss: 0.4638\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4708 - val_loss: 0.4533\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4847 - val_loss: 0.4440\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.4395\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4546 - val_loss: 0.4367\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4417 - val_loss: 0.4347\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.4299\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4244\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 0.4331\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 0.4195\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 0.4137\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4187\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.4148\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4306\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4126\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4068\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.4254\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4334\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 0.4083\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4017\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3915\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.4125\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4002\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.3972\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.4203\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.4174\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3823\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.3965\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3997\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3951\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3738\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3760\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.3985\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.4008\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3967\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.4005\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3767\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.3654\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3698\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3770\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3875\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3803\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3798\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3669\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3701\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.3818\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.3662\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3631\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3563\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3763\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.3553\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3693\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3564\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3664\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.3558\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3627\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.3521\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3521\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3622\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3755\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.3618\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3511\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3491\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3551\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3538\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.3572\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3582\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.3684\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.3427\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.3493\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3653\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3529\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3630\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3468\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3503\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3414\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3597\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3571 - val_loss: 0.3524\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.3526\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.3600\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3570\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3395\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3594\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3451\n",
      "[CV] END ......learning_rate=0.001, n_hidden=2, n_neurons=44; total time=  49.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7705 - val_loss: 6.6830\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 815us/step - loss: nan\n",
      "[CV] END ........learning_rate=0.1, n_hidden=1, n_neurons=21; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7773 - val_loss: 1.6855\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 1.4853\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 2.2445\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4359\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.5027\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.9240\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3546\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 1.6597\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.4468\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 9.5192\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 2.4530\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 2.5224\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.9334\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 4.2769\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 2.2287\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 1.5929\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 24.3413\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9951\n",
      "[CV] END ........learning_rate=0.1, n_hidden=1, n_neurons=21; total time=   7.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 793us/step - loss: nan\n",
      "[CV] END ........learning_rate=0.1, n_hidden=1, n_neurons=21; total time=   4.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3192 - val_loss: 376.8800\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9635 - val_loss: 1248.2115\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.7259 - val_loss: 6279.4771\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 19.2464 - val_loss: 25702.1152\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 70.0868 - val_loss: 118388.6797\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3185.4635 - val_loss: 523685.0312\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4980.0011 - val_loss: 2342943.2500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 44806.5327 - val_loss: 10483769.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 50920.6908 - val_loss: 47072900.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1127435.3428 - val_loss: 222864816.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3305557.6034 - val_loss: 989176000.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2629546.2500\n",
      "[CV] END .......learning_rate=0.01, n_hidden=0, n_neurons=66; total time=   5.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3706 - val_loss: 20.3211\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6158 - val_loss: 21.8118\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5727 - val_loss: 23.0509\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 21.9552\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 21.3127\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 20.9137\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 20.1495\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 20.9458\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 20.0761\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 16.2843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 19.0808\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 21.1477\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 22.5122\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 16.7926\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 18.2995\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 20.1533\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 16.9126\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 16.9343\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 19.5612\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 16.7249\n",
      "121/121 [==============================] - 0s 895us/step - loss: 0.9214\n",
      "[CV] END .......learning_rate=0.01, n_hidden=0, n_neurons=66; total time=   8.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5224 - val_loss: 136.9973\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0917 - val_loss: 167.6389\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2047 - val_loss: 657.3105\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 22.2305 - val_loss: 1352.6234\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0586 - val_loss: 3861.2654\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 15.7907 - val_loss: 6738.2031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 23.5610 - val_loss: 13726.5195\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 479.3272 - val_loss: 27165.5742\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 150.3859 - val_loss: 53434.8555\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 69.0215 - val_loss: 99047.5859\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4603.7984 - val_loss: 191319.8125\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 211.0561\n",
      "[CV] END .......learning_rate=0.01, n_hidden=0, n_neurons=66; total time=   4.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7.7439 - val_loss: 21.9093\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.3471 - val_loss: 19.7302\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.7608 - val_loss: 17.7998\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.5833 - val_loss: 16.0827\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2290 - val_loss: 14.5561\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.1902 - val_loss: 13.2048\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.3744 - val_loss: 11.9990\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.5416 - val_loss: 10.9228\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0395 - val_loss: 9.9543\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1769 - val_loss: 9.0965\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6925 - val_loss: 8.3299\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3231 - val_loss: 7.6360\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7675 - val_loss: 7.0224\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2245 - val_loss: 6.4725\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1120 - val_loss: 5.9714\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8216 - val_loss: 5.5250\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 5.1233\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6984 - val_loss: 4.7629\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6352 - val_loss: 4.4381\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5154 - val_loss: 4.1443\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3212 - val_loss: 3.8739\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3301 - val_loss: 3.6336\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2419 - val_loss: 3.4158\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1756 - val_loss: 3.2183\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1156 - val_loss: 3.0371\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0576 - val_loss: 2.8703\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1006 - val_loss: 2.7240\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 2.5857\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 2.4632\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 2.3498\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8900 - val_loss: 2.2463\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8486 - val_loss: 2.1504\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8382 - val_loss: 2.0650\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8203 - val_loss: 1.9864\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7891 - val_loss: 1.9120\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7893 - val_loss: 1.8474\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7492 - val_loss: 1.7662\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7353 - val_loss: 1.7142\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7332 - val_loss: 1.6626\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 1.6164\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7125 - val_loss: 1.5754\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7082 - val_loss: 1.5344\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 1.4965\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6893 - val_loss: 1.4647\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6755 - val_loss: 1.4342\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6824 - val_loss: 1.4047\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6856 - val_loss: 1.3791\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6469 - val_loss: 1.3551\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 1.3330\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7007 - val_loss: 1.3137\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6463 - val_loss: 1.2943\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6786 - val_loss: 1.2756\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6451 - val_loss: 1.2586\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6442 - val_loss: 1.2414\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 1.2280\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6712 - val_loss: 1.2129\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6445 - val_loss: 1.2006\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 1.1889\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 1.1766\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 1.1641\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 1.1544\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6346 - val_loss: 1.1458\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6324 - val_loss: 1.1374\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 1.1292\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 1.1221\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6435 - val_loss: 1.1150\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 1.1086\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 1.0999\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 1.0947\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6423 - val_loss: 1.0890\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 1.0843\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 1.0790\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 1.0739\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 1.0698\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 1.0649\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6346 - val_loss: 1.0613\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5887 - val_loss: 1.0552\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 1.0517\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 1.0483\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 1.0437\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 1.0412\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 1.0365\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5727 - val_loss: 1.0313\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6026 - val_loss: 1.0273\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 1.0242\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5634 - val_loss: 1.0214\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5883 - val_loss: 1.0168\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5901 - val_loss: 1.0128\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5875 - val_loss: 1.0108\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 1.0089\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6102 - val_loss: 1.0070\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 1.0032\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 1.0022\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5855 - val_loss: 1.0009\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.9975\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5909 - val_loss: 0.9938\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5762 - val_loss: 0.9905\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5857 - val_loss: 0.9876\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5849 - val_loss: 0.9857\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.9827\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5897\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=38; total time=  42.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.4649 - val_loss: 5.8469\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.2941 - val_loss: 5.2417\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.1516 - val_loss: 4.7099\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.1065 - val_loss: 4.2433\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2860 - val_loss: 3.8345\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8672 - val_loss: 3.4769\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.5801 - val_loss: 3.1649\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.4864 - val_loss: 2.8935\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1375 - val_loss: 2.6583\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8866 - val_loss: 2.4554\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6286 - val_loss: 2.2814\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4571 - val_loss: 2.1332\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2009 - val_loss: 2.0083\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0279 - val_loss: 1.9042\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.0648 - val_loss: 1.8188\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7529 - val_loss: 1.7502\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7048 - val_loss: 1.6968\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5947 - val_loss: 1.6571\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.6298\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3702 - val_loss: 1.6137\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3003 - val_loss: 1.6077\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2372 - val_loss: 1.6110\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1841 - val_loss: 1.6225\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1091 - val_loss: 1.6416\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0541 - val_loss: 1.6676\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0272 - val_loss: 1.6998\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9850 - val_loss: 1.7378\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9777 - val_loss: 1.7810\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8861 - val_loss: 1.8290\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8893 - val_loss: 1.8815\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8509 - val_loss: 1.9378\n",
      "121/121 [==============================] - 0s 928us/step - loss: 0.8536\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=38; total time=  14.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.4703 - val_loss: 9.7633\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.7902 - val_loss: 8.8555\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.0372 - val_loss: 8.0542\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7108 - val_loss: 7.3513\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2116 - val_loss: 6.7226\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8185 - val_loss: 6.1676\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4815 - val_loss: 5.6756\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3048 - val_loss: 5.2408\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0197 - val_loss: 4.8493\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7640 - val_loss: 4.4951\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6414 - val_loss: 4.1841\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3575 - val_loss: 3.9005\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1091 - val_loss: 3.6444\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0138 - val_loss: 3.4164\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9288 - val_loss: 3.2086\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 3.0251\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6675 - val_loss: 2.8563\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5923 - val_loss: 2.7029\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5035 - val_loss: 2.5683\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3839 - val_loss: 2.4433\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2929 - val_loss: 2.3296\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3027 - val_loss: 2.2267\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1977 - val_loss: 2.1306\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1216 - val_loss: 2.0442\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0828 - val_loss: 1.9652\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0419 - val_loss: 1.8913\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0655 - val_loss: 1.8289\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.7688\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 1.7158\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 1.6654\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 1.6202\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9005 - val_loss: 1.5791\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8734 - val_loss: 1.5413\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8085 - val_loss: 1.5069\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 1.4752\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7986 - val_loss: 1.4425\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7624 - val_loss: 1.4115\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7855 - val_loss: 1.3865\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7662 - val_loss: 1.3614\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7295 - val_loss: 1.3388\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 1.3195\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6970 - val_loss: 1.2998\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7170 - val_loss: 1.2801\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7057 - val_loss: 1.2640\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6958 - val_loss: 1.2495\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6840 - val_loss: 1.2357\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6836 - val_loss: 1.2195\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6557 - val_loss: 1.2064\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6802 - val_loss: 1.1952\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6498 - val_loss: 1.1843\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6940 - val_loss: 1.1740\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6546 - val_loss: 1.1651\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 1.1545\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6406 - val_loss: 1.1436\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 1.1339\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6454 - val_loss: 1.1241\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6386 - val_loss: 1.1169\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6409 - val_loss: 1.1105\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6422 - val_loss: 1.1035\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 1.0972\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6337 - val_loss: 1.0898\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 1.0847\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 1.0775\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6528 - val_loss: 1.0707\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 1.0641\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5960 - val_loss: 1.0586\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 1.0541\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6173 - val_loss: 1.0493\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5925 - val_loss: 1.0437\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6386 - val_loss: 1.0414\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6464 - val_loss: 1.0383\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 1.0361\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6237 - val_loss: 1.0316\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 1.0264\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5922 - val_loss: 1.0227\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6256 - val_loss: 1.0191\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 1.0154\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6046 - val_loss: 1.0128\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 1.0081\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 1.0054\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5750 - val_loss: 1.0034\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 1.0016\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - val_loss: 0.9984\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.9963\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.9923\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5823 - val_loss: 0.9904\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.9887\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5880 - val_loss: 0.9875\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6031 - val_loss: 0.9849\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.9815\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.9800\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5808 - val_loss: 0.9768\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5762 - val_loss: 0.9755\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.9733\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.9702\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.9684\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.9674\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.9644\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 0.9635\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.9630\n",
      "121/121 [==============================] - 0s 726us/step - loss: 0.5989\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=0, n_neurons=38; total time=  41.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\behzad\\desktop\\jupyter projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [-3.64101499e-01 -7.95659502e-01 -6.63446168e-01 -7.39055077e-01\n",
      " -4.14570282e-01 -3.94589305e-01 -3.81503016e-01             nan\n",
      " -8.76586076e+05 -6.80737336e-01]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 3.2836 - val_loss: 0.9158\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8439 - val_loss: 0.6787\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6940 - val_loss: 0.6283\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6449 - val_loss: 0.5786\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5942 - val_loss: 0.5439\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5587 - val_loss: 0.5162\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5475 - val_loss: 0.4916\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5154 - val_loss: 0.4699\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4919 - val_loss: 0.4524\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - val_loss: 0.4386\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4501 - val_loss: 0.4317\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4360 - val_loss: 0.4254\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4280\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4242\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4210\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4119 - val_loss: 0.4136\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4153\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4111\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3973\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.4186\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.4118\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.4184\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3805\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3853\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3641 - val_loss: 0.3889\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3937\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.3671\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.3823\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3699\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.3803\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3723\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3888\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3552\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3558\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3759\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3486\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.3572\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.3499\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3497\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3435\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3489\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3540\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3484 - val_loss: 0.3579\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3585\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3397 - val_loss: 0.3411\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3398\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3507 - val_loss: 0.3387\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3468\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.3395\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3297\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3377 - val_loss: 0.3374\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3287\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3437\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3227 - val_loss: 0.3321\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3314\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3312\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3280 - val_loss: 0.3255\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3359\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3255 - val_loss: 0.3341\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3295 - val_loss: 0.3274\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3372\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3325\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3323 - val_loss: 0.3337\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3129 - val_loss: 0.3207\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3235 - val_loss: 0.3217\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3235\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3277\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3260\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3190 - val_loss: 0.3269\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3191 - val_loss: 0.3331\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3366\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3235\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3172\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.3302\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.3379\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.3171\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3348\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.3267\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.3307\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3239\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3205\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3281 - val_loss: 0.3088\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3120\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3365\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3197\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 0.3070\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3248\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 0.3277\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3080 - val_loss: 0.3359\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3241\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3103 - val_loss: 0.3190\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3121 - val_loss: 0.3157\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3255 - val_loss: 0.3172\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3217\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3081 - val_loss: 0.3225\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3202 - val_loss: 0.3216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001A550A5EA90>,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.01, 0.001,\n",
       "                                                          0.0001],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                      9, 10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": [i for i in range(100)],\n",
    "    \"learning_rate\": [(10**-i) for i in range(1, 5)] #reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_regressor_model, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(train_set_X, train_set_Y, epochs=100,\n",
    "                  validation_data=(valid_set_X, valid_set_Y),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 26, 'n_hidden': 3, 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36410149931907654"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x1a550a81b70>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 917us/step - loss: 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.31761273741722107"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1a57f3e8da0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 950us/step - loss: 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31761273741722107"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set_X, test_set_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now save this model, evaluate it on the test set, and if you are satisfied with\n",
    "its performance, deploy it to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there are many techniques to explore a search space much more efficiently than randomly. Their core idea is simple: when a region of the space turns out to be good, it should be explored more. This takes care of the zooming process for\n",
    "you and leads to much better solutions in much less time. Here are a few Python libraries you can use to optimize hyperparameters:<br>\n",
    "\n",
    " `Hyperopt`: a popular Python library for optimizing over all sorts of complex search spaces (including real values such as the learning rate, or discrete values such as the number of layers).\n",
    " `Hyperas, kopt or Talos`: optimizing hyperparameters for Keras model (the first two are based on Hyperopt).\n",
    " `Scikit-Optimize (skopt)`: a general-purpose optimization library. The Bayes SearchCV class performs Bayesian optimization using an interface similar to GridSearchCV.\n",
    " `Spearmint`: a Bayesian optimization library.\n",
    " `Sklearn-Deap`: a hyperparameter optimization library based on evolutionary algorithms, also with a GridSearchCV-like interface.\n",
    " And many more!<br>\n",
    "\n",
    "Moreover, many companies offer services for hyperparameter optimization. For example Google Cloud ML Engine has a hyperparameter tuning service. Other companies provide APIs for hyperparameter optimization, such as Arimo, SigOpt, Oscar and many more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter Projects",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
